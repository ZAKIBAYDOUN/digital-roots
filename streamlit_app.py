import streamlit as st
import json
import os
import io
import tempfile
from datetime import datetime
from typing import Dict, Any, Optional, List

import pandas as pd
import requests
from PIL import Image

# === IMPORTS CONDICIONALES SEGUROS ===
FEATURES = {
    "speech": False,
    "ocr": False, 
    "websearch": False,
    "opencv": False
}

# Speech Recognition
try:
    import speech_recognition as sr
    FEATURES["speech"] = True
except ImportError:
    sr = None

# OCR
try:
    import pytesseract
    FEATURES["ocr"] = True
except ImportError:
    pytesseract = None

# Web Search
try:
    from duckduckgo_search import DDGS
    FEATURES["websearch"] = True
except ImportError:
    DDGS = None

# OpenCV
try:
    import cv2
    import numpy as np
    FEATURES["opencv"] = True
except ImportError:
    cv2 = None
    np = None

# === CONFIGURACIÃ“N ===
STATE_FILE = "state.json"
LOG_FILE = "evidence.jsonl"
UPLOADS_DIR = "uploads"

# Crear directorio uploads
os.makedirs(UPLOADS_DIR, exist_ok=True)

# === CONFIGURACIÃ“N DE AGENTES ===
AGENT_CONFIGS = {
    "CEO-DT": {
        "name": "CEO Digital Twin",
        "role": "Ejecutivo EstratÃ©gico",
        "greeting": "Como CEO de Green Hill Canarias"
    },
    "FP&A": {
        "name": "Financial Planning & Analysis",
        "role": "Analista Financiero Senior", 
        "greeting": "Desde la perspectiva financiera"
    },
    "QA/Validation": {
        "name": "Quality Assurance & Validation",
        "role": "Especialista en Calidad",
        "greeting": "En tÃ©rminos de calidad y validaciÃ³n"
    },
    "Governance": {
        "name": "Corporate Governance",
        "role": "Especialista en Gobernanza",
        "greeting": "Desde el punto de vista de gobernanza"
    }
}

# === FUNCIONES MULTIMEDIA ===
def safe_process_audio(audio_data) -> str:
    """Procesa audio de manera segura"""
    if not FEATURES["speech"] or not sr:
        return "âŒ Reconocimiento de voz no disponible. Instala: pip install speechrecognition pyaudio"
    
    try:
        recognizer = sr.Recognizer()
        
        # Guardar temporalmente
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp:
            tmp.write(audio_data.getvalue())
            tmp_path = tmp.name
        
        try:
            # Procesar audio
            with sr.AudioFile(tmp_path) as source:
                audio = recognizer.record(source)
                
            # Intentar espaÃ±ol primero, luego inglÃ©s
            for lang in ['es-ES', 'en-US']:
                try:
                    text = recognizer.recognize_google(audio, language=lang)
                    return text
                except sr.UnknownValueError:
                    continue
                    
            return "âŒ No se pudo reconocer el audio"
            
        finally:
            # Limpiar archivo temporal
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
                
    except Exception as e:
        return f"âŒ Error procesando audio: {str(e)}"

def safe_process_image(image_data) -> Dict[str, Any]:
    """Procesa imagen de manera segura"""
    if not FEATURES["ocr"] or not pytesseract:
        return {"error": "âŒ OCR no disponible. Instala: pip install pytesseract"}
    
    try:
        image = Image.open(image_data)
        
        # InformaciÃ³n bÃ¡sica
        result = {
            "format": str(image.format),
            "size": list(image.size),
            "mode": str(image.mode),
            "extracted_text": ""
        }
        
        # OCR con manejo de errores
        try:
            text = pytesseract.image_to_string(image, lang='spa+eng')
            result["extracted_text"] = text.strip()
        except Exception as ocr_error:
            result["ocr_error"] = str(ocr_error)
            
        return result
        
    except Exception as e:
        return {"error": f"âŒ Error procesando imagen: {str(e)}"}

def safe_web_research(query: str, max_results: int = 5) -> str:
    """BÃºsqueda web segura"""
    if not FEATURES["websearch"] or not DDGS:
        return "âŒ BÃºsqueda web no disponible. Instala: pip install duckduckgo-search"
    
    try:
        results = []
        search_query = f"{query} Green Hill Canarias biotechnology"
        
        # BÃºsqueda con timeout
        with DDGS() as ddgs:
            search_results = ddgs.text(search_query, max_results=max_results)
            
            for r in search_results:
                results.append({
                    "title": r.get("title", "Sin tÃ­tulo")[:100],
                    "body": r.get("body", "Sin descripciÃ³n")[:200],
                    "url": r.get("href", "")
                })
        
        if not results:
            return f"âŒ No se encontraron resultados para: {query}"
            
        # Formatear resultados
        formatted = f"ğŸ” **Resultados para:** {query}\n\n"
        for i, result in enumerate(results, 1):
            formatted += f"**{i}. {result['title']}**\n"
            formatted += f"{result['body']}...\n"
            formatted += f"ğŸ”— {result['url']}\n\n"
            
        return formatted
        
    except Exception as e:
        return f"âŒ Error en bÃºsqueda web: {str(e)}"

def generate_report(topic: str, data: str, agent: str) -> str:
    """Genera informe de investigaciÃ³n"""
    agent_config = AGENT_CONFIGS.get(agent, AGENT_CONFIGS["CEO-DT"])
    current_time = datetime.now().strftime('%d/%m/%Y %H:%M')
    
    return f"""# ğŸ“Š INFORME DE INVESTIGACIÃ“N

**Tema:** {topic}  
**Generado por:** {agent} ({agent_config['role']})  
**Fecha:** {current_time}

---

{agent_config['greeting']}, he realizado una investigaciÃ³n sobre "{topic}".

## ğŸ” INFORMACIÃ“N RECOPILADA

{data}

## ğŸ¯ ANÃLISIS PARA GREEN HILL CANARIAS

### Relevancia EstratÃ©gica
- AlineaciÃ³n con Phase I â€” Pilot & Shadow Mode
- Potencial impacto en compliance EU-GMP  
- Oportunidades en el corredor atlÃ¡ntico

### Recomendaciones
1. **EvaluaciÃ³n tÃ©cnica** detallada
2. **AnÃ¡lisis de viabilidad** financiera
3. **ValidaciÃ³n regulatoria** con equipo QA

## ğŸ“ˆ PRÃ“XIMOS PASOS
- AnÃ¡lisis profundo con equipos especializados
- Consulta con stakeholders clave
- Desarrollo de plan de implementaciÃ³n

---
*Generado por Green Hill Cockpit Multimedia*
"""

# === CONEXIÃ“N LANGGRAPH ===
def get_langgraph_app():
    """Obtiene la app LangGraph de forma segura"""
    try:
        from app.ghc_twin import app
        return app
    except ImportError:
        return None

def process_langgraph_response(result: Any, agent: str, query: str) -> str:
    """Procesa respuesta de LangGraph de manera natural"""
    agent_config = AGENT_CONFIGS.get(agent, AGENT_CONFIGS["CEO-DT"])
    greeting = agent_config["greeting"]
    
    if isinstance(result, dict) and "final_answer" in result:
        answer = result["final_answer"]
        
        # Limpiar formato tÃ©cnico
        clean_answer = str(answer).replace("###", "").replace("```", "").strip()
        
        # Si es muy tÃ©cnica o larga, extraer puntos clave
        if len(clean_answer) > 300 or "Summary:" in clean_answer:
            lines = [l.strip() for l in clean_answer.split('\n') if l.strip()]
            key_points = []
            
            for line in lines[:5]:  # Primeros 5 puntos
                if any(emoji in line for emoji in ['ğŸ¯', 'ğŸ’°', 'ğŸ“Š', 'âš™ï¸', 'â€¢', '-']):
                    clean_line = line.replace('- ', '').replace('|', ' - ').strip()
                    if len(clean_line) > 15:
                        key_points.append(clean_line)
            
            if key_points:
                return f"{greeting}, he analizado tu consulta.\n\n" + "\n\n".join(key_points)
        
        return f"{greeting},\n\n{clean_answer}"
    
    return f"{greeting}, he recibido tu consulta '{query}'. Los sistemas estÃ¡n procesando la informaciÃ³n disponible."

def execute_command(query: str, mode: str, agent: str, context: str = "") -> Dict[str, Any]:
    """Ejecuta comando principal con LangGraph"""
    app = get_langgraph_app()
    
    # Enriquecer query con contexto multimedia
    enhanced_query = query
    if context:
        enhanced_query = f"{query}\n\n**Contexto adicional:**\n{context}"
    
    # Si LangGraph no estÃ¡ disponible
    if not app:
        agent_config = AGENT_CONFIGS.get(agent, AGENT_CONFIGS["CEO-DT"])
        offline_response = f"ğŸ”´ **Sistema Temporalmente Offline**\n\n"
        offline_response += f"Hola, soy el {agent_config['role']} de Green Hill Canarias.\n\n"
        offline_response += f"Consulta recibida: *'{query}'*\n\n"
        
        if context:
            offline_response += f"{context}\n\n"
            
        offline_response += "El sistema LangGraph se estÃ¡ inicializando. Pronto podrÃ© darte un anÃ¡lisis completo."
        
        return {"answer": offline_response, "refs": ["sistema_offline"]}
    
    # Ejecutar con LangGraph
    try:
        payload = {
            "question": enhanced_query,
            "source_type": "investor" if agent == "CEO-DT" else "master",
            "agent": agent,
            "command": mode,
            "state": load_state()
        }
        
        result = app.invoke(payload)
        natural_answer = process_langgraph_response(result, agent, query)
        
        return {
            "answer": natural_answer,
            "refs": result.get("refs", []) if isinstance(result, dict) else []
        }
        
    except Exception as e:
        agent_config = AGENT_CONFIGS.get(agent, AGENT_CONFIGS["CEO-DT"])
        error_response = f"ğŸ”§ **Error TÃ©cnico**\n\n"
        error_response += f"Soy el {agent_config['role']} de Green Hill Canarias.\n\n"
        error_response += f"Error procesando: *'{query}'*\n\n"
        error_response += f"**Detalle:** {type(e).__name__}"
        
        return {"answer": error_response, "refs": ["error_tecnico"]}

# === FUNCIONES DE ESTADO ===
def load_state() -> Dict[str, Any]:
    """Carga el estado del sistema"""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    
    return {
        "phase": "Phase I â€” Pilot & Shadow Mode",
        "zec_rate": 4.0,
        "cash_buffer_to": "",
        "key_dates": {
            "zec_filing": "",
            "gmp_dossier": "", 
            "cash_buffer_to": ""
        }
    }

def save_state(key: str, value: Any) -> None:
    """Guarda estado del sistema"""
    try:
        state = load_state()
        state[key] = value
        
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    except Exception:
        pass  # Fallar silenciosamente

def load_evidence_log() -> pd.DataFrame:
    """Carga log de evidencia"""
    if not os.path.exists(LOG_FILE):
        return pd.DataFrame(columns=["timestamp", "agent", "action", "query", "answer", "refs"])
    
    rows = []
    try:
        with open(LOG_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        rows.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
    except Exception:
        pass
    
    return pd.DataFrame(rows) if rows else pd.DataFrame(columns=["timestamp", "agent", "action", "query", "answer", "refs"])

def append_to_log(entry: Dict[str, Any]) -> None:
    """AÃ±ade entrada al log"""
    try:
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    except Exception:
        pass

# === CONFIGURACIÃ“N STREAMLIT ===
st.set_page_config(
    page_title="ğŸŒ¿ Green Hill Cockpit Multimedia",
    layout="wide",
    page_icon="ğŸ¤",
    initial_sidebar_state="expanded"
)

# === VERIFICAR ESTADO ===
langgraph_app = get_langgraph_app()
connection_status = "ğŸŸ¢ CONNECTED" if langgraph_app else "ğŸ”´ BUILDING..."

# === SIDEBAR ===
st.sidebar.title("âš™ï¸ Control Panel")
st.sidebar.info(f"LangGraph: {connection_status}")

# Estado de funciones multimedia
st.sidebar.subheader("ğŸ“± Capacidades")
feature_labels = {
    "speech": "ğŸ¤ Audio",
    "ocr": "ğŸ“· OCR", 
    "websearch": "ğŸŒ Web Search",
    "opencv": "ğŸ”§ OpenCV"
}

for key, label in feature_labels.items():
    if FEATURES[key]:
        st.sidebar.success(f"{label}: âœ…")
    else:
        st.sidebar.error(f"{label}: âŒ")

# Controles principales
mode = st.sidebar.radio(
    "Modo de Comando", 
    ["/brief", "/deep", "/action", "/sync", "/evidence", "/console", "/research"],
    help="Selecciona el tipo de anÃ¡lisis que deseas"
)

agent = st.sidebar.selectbox(
    "Agente Especializado", 
    list(AGENT_CONFIGS.keys()),
    help="Elige el especialista para tu consulta"
)

# Mostrar info del agente
if agent in AGENT_CONFIGS:
    st.sidebar.info(f"**{AGENT_CONFIGS[agent]['role']}**")

# Variables de estado del proyecto
st.sidebar.subheader("ğŸ“Š Variables del Proyecto")
current_state = load_state()

phase = st.sidebar.text_input("Fase Actual", current_state.get("phase", ""))
zec_rate = st.sidebar.number_input("Tasa ZEC (%)", value=float(current_state.get("zec_rate", 4.0)), step=0.1)

if st.sidebar.button("ğŸ’¾ Guardar Variables"):
    save_state("phase", phase)
    save_state("zec_rate", zec_rate)
    st.sidebar.success("âœ… Estado actualizado")

# === INTERFACE PRINCIPAL ===
st.title("ğŸŒ¿ Green Hill Cockpit Multimedia")
st.markdown(f"**Agente Activo:** {AGENT_CONFIGS[agent]['role']} | **Modo:** {mode}")

# === TABS ===
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ’¬ Chat", 
    "ğŸ¤ Audio", 
    "ğŸ“· Visual", 
    "ğŸŒ Research", 
    "ğŸ“Š Reports"
])

# TAB 1: CHAT
with tab1:
    st.header("ğŸ’¬ ConversaciÃ³n con Agentes")
    
    # Inicializar historial
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # Mostrar conversaciÃ³n
    for entry in st.session_state.chat_history:
        with st.chat_message("user"):
            st.write(entry["question"])
        with st.chat_message("assistant"):
            st.write(entry["answer"])
    
    # Input principal
    user_input = st.chat_input("Escribe tu pregunta o instrucciÃ³n...")
    
    if user_input:
        # Mostrar pregunta del usuario
        with st.chat_message("user"):
            st.write(user_input)
        
        # Procesar y mostrar respuesta
        with st.chat_message("assistant"):
            with st.spinner(f"âš¡ {agent} estÃ¡ procesando..."):
                response = execute_command(user_input, mode, agent)
                answer = response["answer"]
                st.write(answer)
        
        # Guardar en historial y log
        st.session_state.chat_history.append({
            "question": user_input,
            "answer": answer,
            "agent": agent,
            "mode": mode
        })
        
        append_to_log({
            "timestamp": datetime.utcnow().isoformat(),
            "agent": agent,
            "action": mode,
            "query": user_input,
            "answer": answer,
            "refs": response.get("refs", [])
        })
        
        st.rerun()

# TAB 2: AUDIO
with tab2:
    st.header("ğŸ¤ Procesamiento de Audio")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if FEATURES["speech"]:
            st.subheader("ğŸ“¤ Cargar Audio")
            audio_file = st.file_uploader(
                "Selecciona archivo de audio",
                type=['wav', 'mp3', 'm4a', 'ogg'],
                help="Formatos soportados: WAV, MP3, M4A, OGG"
            )
            
            if audio_file:
                st.audio(audio_file)
                
                if st.button("ğŸ¤ Convertir a Texto"):
                    with st.spinner("ğŸ”„ Procesando audio..."):
                        text_result = safe_process_audio(audio_file)
                        
                        if not text_result.startswith("âŒ"):
                            st.success("âœ… Texto extraÃ­do exitosamente")
                            st.write(f"**ğŸ“ Contenido:** {text_result}")
                            
                            # Procesar con agente
                            with st.spinner("ğŸ§  Analizando contenido..."):
                                response = execute_command(
                                    text_result, 
                                    mode, 
                                    agent, 
                                    "ğŸ“ Contenido extraÃ­do de audio"
                                )
                                st.write("**ğŸ¤– AnÃ¡lisis del Agente:**")
                                st.write(response["answer"])
                        else:
                            st.error(text_result)
        else:
            st.error("ğŸ¤ Funcionalidad de audio no disponible")
            st.code("pip install speechrecognition pyaudio")
    
    with col2:
        st.subheader("â„¹ï¸ InformaciÃ³n")
        st.info("**PrÃ³ximamente:**\n- GrabaciÃ³n en tiempo real\n- MÃºltiples idiomas\n- Mejora de calidad")

# TAB 3: VISUAL
with tab3:
    st.header("ğŸ“· Procesamiento Visual y OCR")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if FEATURES["ocr"]:
            st.subheader("ğŸ“¤ Cargar Imagen")
            image_file = st.file_uploader(
                "Selecciona imagen",
                type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
                help="Formatos soportados: JPG, PNG, BMP, TIFF"
            )
            
            if image_file:
                # Mostrar imagen
                image = Image.open(image_file)
                st.image(image, caption="Imagen cargada", use_container_width=True)
                
                if st.button("ğŸ” Extraer Texto (OCR)"):
                    with st.spinner("ğŸ”„ Procesando imagen..."):
                        ocr_result = safe_process_image(image_file)
                        
                        if "error" not in ocr_result:
                            st.success("âœ… Imagen procesada exitosamente")
                            
                            # Mostrar informaciÃ³n de la imagen
                            st.json(ocr_result)
                            
                            # Si hay texto extraÃ­do, analizarlo
                            if ocr_result.get("extracted_text"):
                                extracted_text = ocr_result["extracted_text"]
                                st.write(f"**ğŸ“ Texto extraÃ­do:** {extracted_text}")
                                
                                # Analizar con agente
                                with st.spinner("ğŸ§  Analizando texto extraÃ­do..."):
                                    response = execute_command(
                                        f"Analiza este contenido: {extracted_text}",
                                        mode,
                                        agent,
                                        "ğŸ“· Texto extraÃ­do de imagen via OCR"
                                    )
                                    st.write("**ğŸ¤– AnÃ¡lisis del Agente:**")
                                    st.write(response["answer"])
                            else:
                                st.warning("âš ï¸ No se encontrÃ³ texto en la imagen")
                        else:
                            st.error(ocr_result["error"])
        else:
            st.error("ğŸ“· Funcionalidad OCR no disponible")
            st.code("pip install pytesseract")
    
    with col2:
        st.subheader("â„¹ï¸ CaracterÃ­sticas OCR")
        st.info("""
        **Capacidades:**
        - EspaÃ±ol e InglÃ©s
        - MÃºltiples formatos
        - AnÃ¡lisis automÃ¡tico
        
        **PrÃ³ximamente:**
        - Captura en vivo
        - MÃ¡s idiomas
        - DetecciÃ³n de objetos
        """)

# TAB 4: RESEARCH
with tab4:
    st.header("ğŸŒ InvestigaciÃ³n Web")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        research_query = st.text_input(
            "ğŸ” Â¿QuÃ© quieres investigar?",
            placeholder="Ej: nuevas regulaciones EU-GMP 2025"
        )
        
        research_focus = st.selectbox(
            "ğŸ¯ Enfoque de investigaciÃ³n:",
            [
                "InvestigaciÃ³n general",
                "BiotecnologÃ­a y cannabis", 
                "Regulaciones EU-GMP",
                "Mercado atlÃ¡ntico",
                "InnovaciÃ³n farmacÃ©utica",
                "Compliance y calidad"
            ]
        )
    
    with col2:
        max_results = st.number_input("ğŸ“Š NÃºmero de resultados", 1, 15, 5)
        
        research_button = st.button("ï¿½ï¿½ Investigar", use_container_width=True)
    
    if research_button and research_query:
        if FEATURES["websearch"]:
            with st.spinner("ğŸ” Buscando informaciÃ³n..."):
                # Personalizar bÃºsqueda
                enhanced_query = research_query
                if research_focus != "InvestigaciÃ³n general":
                    enhanced_query = f"{research_query} {research_focus}"
                
                search_results = safe_web_research(enhanced_query, max_results)
                st.write(search_results)
                
                # Analizar resultados si son vÃ¡lidos
                if not search_results.startswith("âŒ"):
                    with st.spinner("ğŸ§  Generando anÃ¡lisis estratÃ©gico..."):
                        analysis_query = f"Analiza esta investigaciÃ³n para Green Hill Canarias: {research_query}"
                        response = execute_command(
                            analysis_query,
                            mode, 
                            agent,
                            search_results
                        )
                        st.write("**ğŸ¤– AnÃ¡lisis EstratÃ©gico:**")
                        st.write(response["answer"])
        else:
            st.error("ï¿½ï¿½ BÃºsqueda web no disponible")
            st.code("pip install duckduckgo-search")
    elif research_button and not research_query:
        st.warning("âš ï¸ Ingresa un tÃ©rmino de investigaciÃ³n")

# TAB 5: REPORTS  
with tab5:
    st.header("ğŸ“Š Informes y Evidencia")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ Generar Informe")
        
        report_topic = st.text_input(
            "ğŸ“‹ Tema del informe:",
            placeholder="Ej: Estado de compliance EU-GMP"
        )
        
        report_data = st.text_area(
            "ğŸ“„ Datos adicionales (opcional):",
            height=100,
            placeholder="InformaciÃ³n adicional para el informe..."
        )
        
        if st.button("ğŸ“Š Generar Informe Completo"):
            if report_topic:
                # Auto-investigar si no hay datos
                if not report_data and FEATURES["websearch"]:
                    with st.spinner("ğŸ“– Recopilando informaciÃ³n..."):
                        report_data = safe_web_research(report_topic, 5)
                
                # Generar informe
                with st.spinner("ğŸ“ Generando informe..."):
                    report = generate_report(report_topic, report_data or "InformaciÃ³n base disponible", agent)
                    st.markdown(report)
                    
                    # BotÃ³n de descarga
                    filename = f"informe_{report_topic.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
                    st.download_button(
                        label="ğŸ’¾ Descargar Informe",
                        data=report,
                        file_name=filename,
                        mime="text/markdown",
                        use_container_width=True
                    )
            else:
                st.warning("âš ï¸ Ingresa un tema para el informe")
    
    with col2:
        st.subheader("ğŸ“ Log de Evidencia")
        
        evidence_df = load_evidence_log()
        
        if not evidence_df.empty:
            # Mostrar estadÃ­sticas
            st.metric("Total de consultas", len(evidence_df))
            
            # Filtros
            agent_filter = st.selectbox("Filtrar por agente:", ["Todos"] + list(AGENT_CONFIGS.keys()))
            
            # Aplicar filtro
            if agent_filter != "Todos":
                filtered_df = evidence_df[evidence_df["agent"] == agent_filter]
            else:
                filtered_df = evidence_df
            
            # Mostrar tabla
            st.dataframe(
                filtered_df[["timestamp", "agent", "action", "query"]].tail(20),
                use_container_width=True
            )
            
            # OpciÃ³n de descarga
            csv_data = filtered_df.to_csv(index=False)
            st.download_button(
                "ğŸ’¾ Descargar Log CSV",
                csv_data,
                f"evidence_log_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                "text/csv",
                use_container_width=True
            )
        else:
            st.info("ğŸ“‹ No hay evidencia registrada aÃºn")

# === FOOTER ===
st.markdown("---")

footer_col1, footer_col2, footer_col3 = st.columns(3)

with footer_col1:
    st.markdown("ğŸŒ¿ **Green Hill Cockpit Multimedia**")

with footer_col2:
    st.markdown(f"ğŸ”— LangGraph: {connection_status}")

with footer_col3:
    st.markdown("âš¡ *Powered by AI & LangGraph*")
